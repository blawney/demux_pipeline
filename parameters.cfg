[DEFAULT]

# the name of the SMTP server to send completion email
smtp_server = pascal.dfci.harvard.edu

# the port to use on the SMTP server
smtp_port = 25 

[CLOUD]

# the bucket where we keep CCCB records like the tracking file
master_bucket = cccb-seq-main

# the project ID for Google Cloud
google_project_id = cccb-data-delivery

# name of the file that tracks the clients and their buckets
master_file = sequencing_records.json

# the NAME of the "folder" where fastq files will live. <bucket>/<fastq_root>/*.fastq.gzf
cloud_fastq_root = fastq

# the NAME of the "folder" where fastQC reports will live.  <bucket>/<fastqc_root>/<sample fastQC dirs>
cloud_fastqc_root = fastQC

# the public root for accessing files, used to rewrite relative links in the fastQC HTML report
storage_root = https://storage.cloud.google.com

# a file tag for the edited fastQC HTML report
gcloud_edit_suffix = .gcloud_edit

# contains connection details for google cloud.  Secret file.
credential_file = /ifs/labs/cccb/projects/cccb/pipelines/demux_and_delivery/credentials.json

# the name of a directory (in the project directory) which will contain symlinks to the final fastq files
# this allows easier rsync capabilities for the cloud upload
final_symlinked_fastq_directory = fastq_symlinks


[DEMUX]

# the intended name prefix for the directories containing each sample's FASTQ files
sample_dir_prefix = Sample_

# the final location of the data- projects are then organized by year, month
destination_path = /cccbstore-rc/projects/cccb/projects

# the output/delivery directory:
delivery_home = /cccbstore-rc/projects/cccb/outgoing/frd/

# the outgoing location (the publicly exposed link base):
external_url = https://cccb-download.dfci.harvard.edu/frd/

# the path to the fastQC software:
fastqc_path = /cccbstore-rc/projects/cccb/apps/FastQC/fastqc 

# the name of the output directory that will be created for the FASTQ files
demux_output_dir = bcl2fastq2_output

# a string for marking an intermediate fastq file
tmp_fastq_tag = tmp

# a string for marking a final fastq file
final_fastq_tag = final

# the name for a sample annotation file (which is used in downstream processes)
default_sample_listing_filename = samples.no_groups.txt

# flowcell prefix is how we keep track of multiple sequencing runs for the same project.  Each flowcell
# is tagged sequentially as fc1, fc2, etc
flowcell_prefix = fc

# the name for a file which maps the samples back to their original lane-specific fastq files (prior to being concatenated)
# used for processes where we need to keep track of read groups, etc. such as with GATK-based variant calls
fastq_lane_map_file = lane_specific_fastq_sources.tsv

# the name of a directory which will contain ALL of the lane-specific fastq files.
# analysts will decide whether to eventually get rid of them or not.
lane_specific_fastq_directory = lane_specific_fastq

# the name of a project descriptor file that can be used in other downstream processes
project_descriptor = project_details.json

# each fastqc directory has this suffix
fastqc_dir_suffix = _fastqc

# the fastqc data file to make plots
fastqc_data = fastqc_data.txt

# the html page created by fastQC
fastqc_report = fastqc_report.html

# the path to the demux software
# demux_path = /cccbstore-rc/projects/cccb/apps/bcl2fastq-v2.16/bin/bcl2fastq
demux_path = /cccbstore-rc/projects/cccb/apps/bcl2fastq-v2.15/bin/bcl2fastq

# sometimes upload process can be interrupted, so we might need to restart the upload
# this goes here since it's related to the demux process
max_cloud_upload_attempts = 5

[TRACKING]
# a file which serves as a database for data retention.  Either absolute path, or relative 
data_retention_db = data_retention.db

# a backup (one or more) of the database in another location.  
# IMPORTANT: needs a comma at the end, even if only a single backup location.  
backup_db_list = data_retention.db,

# the number of days to hold the data in the cloud storage bucket
retention_period = 30

# the days (until removal) that the client will be reminded:
reminder_intervals = 14,7,3

# the format of the date that will be stored in the tracking database (to work with datetime strftime/strptime methods)
# note that for the parser to work, need to double the %
date_format = %%m/%%d/%%Y

# a file where the pipeline will write removal commands
# note that this file just stores the commands, but someone SHOULD be checking them over and running them manually.
# Could be an absolute path or relative to this directory
data_cleanup_command_log = data_cleanup.sh

# a template for the reminder email:
reminder_email_template = reminder_email_template.txt

# a template for the notification (to the CCCB) that a project is marked for deletion
cccb_deletion_notification_template = deletion_notification_template.txt

# the cost (per gb, per month) for google storage
storage_cost = 0.01

# the delivery page
cccb_download_site = http://cccb-delivery.tm4.org

# notifications- people who should receive info about projects to cleanup/delete.  If only one entry, still need a comma on the end
cccb_internal_notification_list = blawney@jimmy.harvard.edu,

# the subject of the email sent to clients
client_notification_subject = CCCB data notification
